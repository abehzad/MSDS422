{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Behzad_Assignment_7.3.ipynb","provenance":[{"file_id":"1s1i5j7uOMW58pKC847CtvcjmPemIG2_r","timestamp":1573422101477},{"file_id":"1NYk1D-vgsnfhdUzDS3aY5BjwALwpT_LO","timestamp":1573420516291}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CIEhPW8ippwH","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"jIhJ2ax-sgOa","colab_type":"text"},"source":["## **Image Classification Using Convolutional Neural Networks (CNN):** \n","*  In this experiment, a Dogs versus Cats data set will be used. The data set contains data for thousands of color images for dogs and cats. \n","* Multiple convolutional neural networks will be built and tested to classify the images in the dataset. Train and test set accuracies and losses will be captured, as well as processing times for training each model. The number of layers and nodes per layer will serve as key parameters that will differentiate each model, and the accuracies, loss, and processing times will be compared. Log loss will be the main metric used to compare models. \n","* Each image is a part of 2 folders, one for training and the other for testing. Images in the training folder has labels as a part of the file name.\n","* The training folder contains 25,000 images of dogs and cats. The test folder contains 12,500 images, named according to a numeric id [2].\n","* For each image in the test set, a probability is predicted: 1 for dog, 0 for cat.\n","*  Image classifiers will be developed using convolutional layers and max pooling layers that can be used to predict which of the images is a cat or a dog.\n","*   The goal of this benchmark experiment is to assess the effectiveness of convolutional neural networks using different topologies. \n","*   Benchmark experiment is based on a 2x2 factorial design with two levels on each of two experimental factors. \n","* Models will be evaluated on the test set that will be scored by a third party (Kaggle).\n"]},{"cell_type":"markdown","metadata":{"id":"WEri4xB3Idmn","colab_type":"text"},"source":["## **What is a Convolutional Neural Network (CNN)?**\n","Convolutional Neural Networks, or CNNs, are deep learning algorithms that are inspired by our own brain's visual cortex. This variant neural network, from  a fully connected deep neural network, power image services, self-driving cars, and more. They are also used in voice recognition and natural language processing. CNNs are modeled off of our visual cortex in that they react to local receptive fields, where receptive fields of different neurons overlap, and together they tie together the whole receptive field [1]. Higher-level neurons have larger receptive fields and are based on the outputs of neighboring lower-level neurons, and each neuron is connected to a few neurons from the previous layer. In other words, neurons in the first convolutional layer are not connected to every single pixel in their receptive fields. That is each neuron in the subsequent layer is connected only to neurons located within a small rectangle from the previous layer. This architecture is able to detect complex patterns in almost any area of the visual field.\n","\n","In a CNN a neuron's weights are represented as a small image the size of the receptive field. They are called filters or convolutional kernels. A filter will generally have neurons using these weights ignore everything in their receptive field, such as in a representation of a black shape with a white line that crosses through it. The neurons will ignore everything except for the white line. A layer of neurons using the same filter, is thus called a feature map, which highlights the areas in an image that are most similar to the filter. A CNN during training finds the most useful filters for its task, and combines them into more complex patterns [1]. A convolutional layer will have stacks of multiple feature maps where different feature maps will have different parameters allowing it to detect features anywhere in its inputs. Once a CNN has learned to distinguish a pattern in one location, it can distinguish it from another location. Additionally, input images are also composed of multiple sublayers, representing one color per channel.    \n","\n","On top of convolutional layers, a CNN will generally also have layers called pooling layers, that subsample, or shrink the image to reduce the computational load, and the number of parameters to reduce overfitting [1]. As with convolutional layers, a pooling layer is connected to the outputs of a limited number of neurons in the previous layer, yet it will have no weights. It aggregates all the inputs using a function such as the max or mean. A typical CNN architecture will have convolutional layers, followed by pooling layers, and a feed forward neural network that is added at the end, which are composed of a few fully connected layers. A final layer will then output the prediction.     \n"]},{"cell_type":"markdown","metadata":{"id":"0oth9hH_s061","colab_type":"text"},"source":["## **Initial Setup:**"]},{"cell_type":"markdown","metadata":{"id":"qievgEHRtAr7","colab_type":"text"},"source":["### **Import Libraries:**"]},{"cell_type":"code","metadata":{"id":"MneCLwPpUmN5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"2908a98e-c06c-4086-9abb-6539d85e79ec","executionInfo":{"status":"ok","timestamp":1575390221838,"user_tz":300,"elapsed":5157,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","#TensorFlow \n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import os, os.path, shutil\n","from google.colab import files\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image\n","from keras.preprocessing.image import img_to_array, load_img\n","from keras import layers\n","from keras.models import load_model\n","from keras import backend as K\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","#from tensorflow.keras.callbacks import ModelCheckpoint\n","#from keras.callbacks import TensorBoard\n","#For math\n","import numpy as np\n","#For data\n","import pandas as pd\n","#For visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","color = sns.color_palette()\n","sns.set_style('darkgrid')\n","#For modeling\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","#Timer for execution time\n","import time\n","from timeit import default_timer as timer\n","#For random shuffling\n","import random\n","#For data transfer\n","import json\n","#For logging\n","from datetime import datetime"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RqXkQr01ytK5","colab_type":"text"},"source":["### **TensorBoard Tunnel for Visualization on Local Machine:**"]},{"cell_type":"code","metadata":{"id":"B3DFrqJ4yNU7","colab_type":"code","outputId":"57484d8b-82c3-4052-b64b-892ebed95cee","executionInfo":{"status":"ok","timestamp":1575390235725,"user_tz":300,"elapsed":19021,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":243}},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2019-12-03 16:23:42--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.235.200.97, 3.231.170.111, 52.20.12.96, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.235.200.97|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  6.49MB/s    in 2.0s    \n","\n","2019-12-03 16:23:49 (6.49 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LNVQT_EayNt4","colab_type":"code","colab":{}},"source":["LOG_DIR = './log'\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR)\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZNyzvVhyNyv","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXhg0wUgyOAX","colab_type":"code","outputId":"9eb0437e-5adb-41b1-8bbd-2213b035e385","executionInfo":{"status":"ok","timestamp":1575390238980,"user_tz":300,"elapsed":22247,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["http://bb2f8eb7.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dZ2RBWff6MX-","colab_type":"code","colab":{}},"source":["# For logging\n","log = './log' + '/' +  datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n","tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=log)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swVc_3Ocy1Sd","colab_type":"text"},"source":["### **Define Functions:**"]},{"cell_type":"markdown","metadata":{"id":"D1XgXBAVlPGv","colab_type":"text"},"source":["**Confusion Matrix:**"]},{"cell_type":"code","metadata":{"id":"i2LxErcdb7cO","colab_type":"code","colab":{}},"source":["# Used for confusion matrix visualization\n","def plot_confusion_matrix(matrix, annot, axes, color): \n","    sns.heatmap(matrix, annot=annot,ax=axes, fmt='g', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], cmap=color); #annot=True to annotate cells\n","    b, t = plt.ylim() # Fix cutoff\n","    b += 0.5 # Add 0.5 to the bottom\n","    t -= 0.5 # Subtract 0.5 from the top\n","    plt.ylim(b, t) # update the ylim(bottom, top) values\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLISjNjklUpa","colab_type":"text"},"source":["**Classification Report Heatmap:**"]},{"cell_type":"code","metadata":{"id":"zZsG4g8Xb7xu","colab_type":"code","colab":{}},"source":["# Used to visualize classification reports for better visibility\n","def plot_classification_report(y_tru, y_prd, figsize=(10, 10), ax=None):\n","\n","    plt.figure(figsize=figsize)\n","\n","    xticks = ['Precision', 'Recall', 'f1-score']\n","    #yticks = list(np.unique(y_tru))\n","    yticks = ['Cat', 'Dog']\n","    yticks += ['AVG']\n","\n","    rep = np.array(precision_recall_fscore_support(y_tru, y_prd))[:3,:].T\n","    avg = np.mean(rep, axis=0)\n","    rep = np.insert(rep, rep.shape[0], avg, axis=0)\n","\n","    sns.heatmap(rep, annot=True, cbar=True, fmt='g', cmap='Blues', xticklabels=xticks, yticklabels=yticks, ax=ax)\n","    b, t = plt.ylim() # Fix cutoff\n","    b += 0.5 # Add 0.5 to the bottom\n","    t -= 0.5 # Subtract 0.5 from the top\n","    plt.ylim(b, t) # update the ylim(bottom, top) values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K0QGehNPlbRL","colab_type":"text"},"source":["**Custom Metrics for F1 Scores, Precision, and Recall:**"]},{"cell_type":"code","metadata":{"id":"irlzizscbWuj","colab_type":"code","colab":{}},"source":["# Function for precision, recall, and f1 scores\n","\n","def recall_m(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","def precision_m(y_true, y_pred):\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7IpfTS8cxzMe","colab_type":"text"},"source":["### **Data Preparation:**"]},{"cell_type":"markdown","metadata":{"id":"2RdoRWRtpJhk","colab_type":"text"},"source":["**Import Images:**"]},{"cell_type":"code","metadata":{"id":"Gg3qxktGVx1Z","colab_type":"code","colab":{}},"source":["!mkdir .kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbGGW5jddSCA","colab_type":"code","outputId":"b3c07401-277a-4242-d8f8-b076687602da","executionInfo":{"status":"ok","timestamp":1575390247966,"user_tz":300,"elapsed":31182,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ls -a"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  \u001b[01;34m.config\u001b[0m/  \u001b[01;34m.kaggle\u001b[0m/  \u001b[01;32mngrok\u001b[0m*  ngrok-stable-linux-amd64.zip  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ESoGEWKEU7Oc","colab_type":"code","colab":{}},"source":["token = {\"username\":\"abehzad\",\"key\":\"b14e0c676f302746ec4eeb43dd46025c\"}\n","with open('/content/.kaggle/kaggle.json', 'w') as file:\n","    json.dump(token, file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDrSeiCvWJBI","colab_type":"code","colab":{}},"source":["!chmod 600 /content/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mIxCoM9NU7iu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1bd5f920-6abf-4dd6-bfde-2128e5ca2b2f","executionInfo":{"status":"ok","timestamp":1575390255785,"user_tz":300,"elapsed":38987,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}}},"source":["!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"],"execution_count":14,"outputs":[{"output_type":"stream","text":["cp: cannot create regular file '/root/.kaggle/kaggle.json': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CVjlBz4qU7lS","colab_type":"code","outputId":"62e43b83-4ec6-4bae-c672-f0da8f8a2dfe","executionInfo":{"status":"ok","timestamp":1575390260291,"user_tz":300,"elapsed":43479,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 5, in <module>\n","    from kaggle.cli import main\n","  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n","    api.authenticate()\n","  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n","    self.config_file, self.config_dir))\n","IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GdDKwhMeU7n4","colab_type":"code","outputId":"58f0a0b4-ae26-4ccf-d51f-bf4909260060","executionInfo":{"status":"ok","timestamp":1575390272490,"user_tz":300,"elapsed":55665,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["!unzip \\*.zip"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DFqvondU7qe","colab_type":"code","outputId":"8f002b20-01c8-4ab2-dae3-b49d06b98fa1","executionInfo":{"status":"ok","timestamp":1575390276457,"user_tz":300,"elapsed":59615,"user":{"displayName":"Alexander Behzad","photoUrl":"","userId":"01622596774680678231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls -a"],"execution_count":17,"outputs":[{"output_type":"stream","text":[".  ..  .config\t.kaggle  ngrok\tngrok-stable-linux-amd64.zip  sample_data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HPBfdJo3qwxB","colab_type":"text"},"source":["### **Split Training Data Into Train Set and Validation Set:**"]},{"cell_type":"code","metadata":{"id":"xYebqInmaVu1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":165},"outputId":"1bd95182-c16e-45e9-aafa-f125b90c7849"},"source":["file_names = os.listdir('./train')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-6dca779be449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train'"]}]},{"cell_type":"code","metadata":{"id":"Sq6tf-QYcqTb","colab_type":"code","colab":{}},"source":["len(file_names)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YiOe3vwLTlrx","colab_type":"text"},"source":["**Randomly Shuffle Images and Split:**"]},{"cell_type":"code","metadata":{"id":"AKyuXS5rcqj-","colab_type":"code","colab":{}},"source":["#Function to split training file into a training set and validation set. \n","percentage_of_train = 0.75    \n","\n","def split_dataset_in_train_and_valid( filenames, percentage):\n","  \n","  total_images = len(filenames)\n","  total_train = int(total_images * percentage_of_train)\n","  \n","  set_train = []\n","  \n","  random.seed(42)\n","  while (len(set_train) != total_train):     \n","    num_image = random.randrange(total_images)\n","    if num_image not in set_train:\n","      set_train.append(num_image)\n","\n","  set_valid = []\n","  for i in range(total_images):\n","    if i not in set_train:\n","      set_valid.append(i)\n","    \n","  images_train =[]\n","  for i in set_train:    \n","    images_train.append(filenames[i])\n","   \n","  images_valid =[]\n","  for i in set_valid:    \n","    images_valid.append(filenames[i])\n","  \n","  return (images_train, images_valid)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wL93mQTf5kV","colab_type":"code","colab":{}},"source":["train_train_valid = (split_dataset_in_train_and_valid (file_names, percentage_of_train))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsJDdjDegcje","colab_type":"code","colab":{}},"source":["train_train = train_train_valid[0]\n","train_val = train_train_valid[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-pvfWVjT3ZR","colab_type":"text"},"source":["**Make Subdirectories and Move Images:**"]},{"cell_type":"code","metadata":{"id":"wBQQp4AJpr_G","colab_type":"code","colab":{}},"source":["os.makedirs('./train_train')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3997A6wp1KA","colab_type":"code","colab":{}},"source":["os.makedirs('./train_valid')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkbSeuxerkKQ","colab_type":"code","colab":{}},"source":["for i in train_train:\n","  shutil.move('./train/'+ i, './train_train')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n2_nd7yQpf38","colab_type":"code","colab":{}},"source":["for i in train_val:\n","  shutil.move('./train/'+ i, './train_valid')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pe7MO3kurUBz","colab_type":"code","colab":{}},"source":["len(os.listdir('./train_train'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_3sheLQrsGr","colab_type":"code","colab":{}},"source":["len(os.listdir('./train_valid'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O1NjI8sgrLMZ","colab_type":"text"},"source":["**Split Training Set, Validation Set, and Test Set Into Class Subfolders:**"]},{"cell_type":"code","metadata":{"id":"4Wp9IvD2sCwi","colab_type":"code","colab":{}},"source":["# Split training set into classes\n","\n","folder_path = './train_train'\n","\n","images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","\n","for image in images:\n","    folder_name = image.split('.')[0]\n","\n","    new_path = os.path.join(folder_path, folder_name)\n","    if not os.path.exists(new_path):\n","        os.makedirs(new_path)\n","\n","    old_image_path = os.path.join(folder_path, image)\n","    new_image_path = os.path.join(new_path, image)\n","    shutil.move(old_image_path, new_image_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x3bIGW2vsIHm","colab_type":"code","colab":{}},"source":["# Split validation set into classes\n","\n","folder_path = './train_valid'\n","\n","images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","\n","for image in images:\n","    folder_name = image.split('.')[0]\n","\n","    new_path = os.path.join(folder_path, folder_name)\n","    if not os.path.exists(new_path):\n","        os.makedirs(new_path)\n","\n","    old_image_path = os.path.join(folder_path, image)\n","    new_image_path = os.path.join(new_path, image)\n","    shutil.move(old_image_path, new_image_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5RSZgno2dlh","colab_type":"text"},"source":["**Create Subdirectory for Test Set Images:**"]},{"cell_type":"code","metadata":{"id":"kzQ_NnEE3daH","colab_type":"code","colab":{}},"source":["len(os.listdir('./test/'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhcS79KD3__k","colab_type":"code","colab":{}},"source":["os.mkdir('./test_files')\n","os.mkdir('./test_files/test_images')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"usOe3L8e2wbq","colab_type":"code","colab":{}},"source":["image_files = os.listdir('./test')\n","for i in image_files:\n","  shutil.move('./test/'+ i, './test_files/test_images')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2x3O4Ms4dmT","colab_type":"code","colab":{}},"source":["len(os.listdir('./test_files/test_images'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-jRecvLv6aV","colab_type":"code","colab":{}},"source":["shutil.rmtree('./test')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0fpZ1WNaSUnc","colab_type":"text"},"source":["**The Data:**"]},{"cell_type":"code","metadata":{"id":"S0oQoUIa2zyF","colab_type":"code","colab":{}},"source":["num_cats_tr = len(os.listdir('train_train/cat'))\n","num_dogs_tr = len(os.listdir('train_train/dog'))\n","\n","num_cats_val = len(os.listdir('./train_valid/cat'))\n","num_dogs_val = len(os.listdir('./train_valid/dog'))\n","\n","train_size = len(os.listdir('./train_train/cat')) +len(os.listdir('./train_train/dog'))\n","val_size = len(os.listdir('./train_valid/cat')) +len(os.listdir('./train_valid/dog'))\n","\n","print('Total training cat images:', num_cats_tr)\n","print('Total training dog images:', num_dogs_tr)\n","\n","print('Total validation cat images:', num_cats_val)\n","print('Total validation dog images:', num_dogs_val)\n","print(\"--\")\n","print(\"Total training images:\", train_size)\n","print(\"Total validation images:\", val_size)\n","print(\"Total test images:\", len(os.listdir('./test_files/test_images')))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1XGvMSp1OPb","colab_type":"text"},"source":["### **Image Scaling for Test Set:**"]},{"cell_type":"code","metadata":{"id":"rvfo2ry_6Im-","colab_type":"code","colab":{}},"source":["IMG_HEIGHT = 224\n","IMG_WIDTH = 224"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AEDfBRNY21BD","colab":{}},"source":["test_image_generator = ImageDataGenerator(rescale=1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bQQxoX2v21Bh","colab":{}},"source":["test_data_gen = test_image_generator.flow_from_directory(batch_size=1,\n","                                                           directory=r'./test_files/',\n","                                                           shuffle=False,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode=None,\n","                                                           seed=42)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OncUUm-wtzoC","colab_type":"text"},"source":["### **Image Scaling For Training and Validation Sets:**"]},{"cell_type":"code","metadata":{"id":"W-3izogMXy3r","colab_type":"code","colab":{}},"source":["batch_size = 32\n","epochs = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RzcPjxIDhUyB","colab_type":"code","colab":{}},"source":["train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n","validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4LcTxMnhdW3","colab_type":"code","colab":{}},"source":["train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory='./train_train',\n","                                                           shuffle=True,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary',\n","                                                           seed=42)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OywVG_WTtGJy","colab_type":"code","colab":{}},"source":["val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory='./train_valid',\n","                                                              shuffle=True,\n","                                                              color_mode='rgb',\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='binary',\n","                                                              seed=42\n","                                                              )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cClPRLbSsFcD","colab_type":"text"},"source":["## **Visualizing the Images:**"]},{"cell_type":"code","metadata":{"id":"U2sY5egBtSW4","colab_type":"code","colab":{}},"source":["# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n","def plotImages(images_arr):\n","    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, ax in zip( images_arr, axes):\n","        ax.imshow(img)\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kNSSZt8otSRi","colab_type":"code","colab":{}},"source":["sample_training_images, _ = next(train_data_gen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"krGH4HOCtSaX","colab_type":"code","colab":{}},"source":["plotImages(sample_training_images[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hzqycV7tczJ","colab_type":"text"},"source":["## **Convulutional Neural Network Experimental Factor 1:**\n"," - Five convolutional layers, five max pooling layers, and one fully connected layer was used in the first experimental factor. Two models were used in the first experimental factor. \n"," - Default settings were used for the max pooling layers. Convolutional layers all had zero padding, using relu activation. Different nodes were used for each convolutional layer going from 3, 64, 128, and ending at 512.\n"," - The fully connected layer had 512 nodes, and activation was also set to relu.\n"," - The output layer used sigmoid activation, as this was the recommended activation for binary classification.\n"," - While the second model used basically the same layers (had an added average pooling layer at the end), it utilized regularization and batch normalization to prevent overfitting. \n"," - For the second model, batch normalization was used after every max pooling layer and for the fully connected layer, and a dropout of 0.25 or 0.50 was also used.\n"," - Early stopping was used for both models that were set to the least amount of loss. Models were ran over 50 epochs with a batch size of 32, with 585 steps per epoch for training, and 195 steps for validation. \n"," - Results showed that although the second model took almost double the processing time (15.30 minutes versus 31.11), there were significant improvements in accuracy and loss (95.68% and 0.1176 versus 98.22% and 0.0494).\n"," - Though additional regularization techniques and tweaks in hyperparameter settings could have been used, employing dropout and batch normalization showed a marked difference, indicating that at the expense of time and resources, it may be a worthwhile expenditure. "]},{"cell_type":"markdown","metadata":{"id":"39CGen-FuP4_","colab_type":"text"},"source":["### **Model 1A:**\n"," - No regularization or normalization.\n"," - Five convolutional layers, five max pooling layers, and one fully connected layer. \n"," - Nodes for convolutional layers are 3, 64, 128, and 512.\n"," - Fully connected layer has 512 nodes.\n"," - Early stopping set to 5 epochs where the least amount of loss is restored for testing.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"meTKwQJjnalc","colab":{}},"source":["# Set up model layers\n","tf.keras.backend.clear_session()\n","\n","model_1A = Sequential([\n","    Conv2D(3, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","    MaxPooling2D(),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogEfkJ_5tShm","colab_type":"code","colab":{}},"source":["#Compile model and define optimizer, loss, and, metrics\n","model_1A.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',f1_m, precision_m, recall_m])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBrmg3xmtSk9","colab_type":"code","colab":{}},"source":["model_1A.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJ9v5NrKuJrS","colab_type":"code","colab":{}},"source":["#Fit model with execution time recorded\n","start = timer()\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n","history_1A = model_1A.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch=train_size // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=val_size // batch_size,\n","    callbacks = [es, tbCallBack]\n",")\n","end = timer()\n","exec_time_model_1a = (end - start)/60\n","\n","print('Total Processing Time in Minutes:', exec_time_model_1a)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBAT62nRzxEl","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kxIWa6pD_lvU","colab_type":"text"},"source":["**Metrics and Visualizations:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eJsyTG1omfm_","colab":{}},"source":["stats_train_1A = model_1A.evaluate(train_data_gen, verbose=1)\n","stats_val_1A = model_1A.evaluate(val_data_gen, verbose=1)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FgMLh1tl1dc","colab_type":"text"},"source":["**Learning Curves:**\n"," - Learning curves below show signs of overfitting, as loss increases over time, while training accuracy starts to plateau."]},{"cell_type":"code","metadata":{"id":"ExN73AhSuJ9i","colab_type":"code","colab":{}},"source":["acc_1A = history_1A.history['accuracy']\n","val_acc_1A = history_1A.history['val_accuracy']\n","\n","loss_1A = history_1A.history['loss']\n","val_loss_1A = history_1A.history['val_loss']\n","\n","epochs_range = range(11)\n","\n","plt.figure(figsize=(12, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc_1A, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_1A, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy: Model 1A')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss_1A, label='Training Loss')\n","plt.plot(epochs_range, val_loss_1A, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss: Model 1A')\n","\n","plt.suptitle('Accuracy and Loss: Model 1A', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v5crK__Tnoqy","colab_type":"text"},"source":["**F1 Scores, Precision, and Recall:**\n"," - F1 scores, precision and recall show slippage over time. This is also an indication of an overfitting model. "]},{"cell_type":"code","metadata":{"id":"-2yeXTQMur87","colab_type":"code","colab":{}},"source":["f1_1A = history_1A.history['f1_m']\n","val_f1_1A = history_1A.history['val_f1_m']\n","\n","precision_1A = history_1A.history['precision_m']\n","val_precision_1A = history_1A.history['val_precision_m']\n","\n","recall_1A = history_1A.history['recall_m']\n","val_recall_1A = history_1A.history['val_recall_m']\n","\n","\n","f,(ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 8))\n","plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=None)\n","\n","ax1.plot(epochs_range, f1_1A, label='Training F1 Score')\n","ax1.plot(epochs_range, val_f1_1A, label='Validation F1 Score')\n","ax1.legend(loc='lower right')\n","ax1.title.set_text('Training and Validation F1 Score: Model 1A')\n","\n","ax2.plot(epochs_range, precision_1A, label='Training Precision')\n","ax2.plot(epochs_range, val_precision_1A, label='Validation Precision')\n","ax2.legend(loc='lower right')\n","ax2.title.set_text('Training and Validation Precision: Model 1A')\n","\n","ax3.plot(epochs_range, recall_1A, label='Training Recall')\n","ax3.plot(epochs_range, val_recall_1A, label='Validation Recall')\n","ax3.legend(loc='lower right')\n","ax3.title.set_text('Training and Validation Recall: Model 1A')\n","\n","plt.suptitle('F1 Score, Precision, Recall: Model 1A', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZVgAbgoPSgc","colab_type":"code","colab":{}},"source":["#Generate predictions from validation data from last checkpoint\n","val_data_gen.reset()\n","y_pred_1A = model_1A.predict_generator(val_data_gen, val_size // batch_size + 1)\n","y_pred_1A = np.round_(y_pred_1A)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AioiAoArQDoy","colab_type":"code","colab":{}},"source":["#Get true labels\n","y_true = val_data_gen.classes[val_data_gen.index_array]\n","y_true_lab = list(val_data_gen.class_indices.keys())   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dfTKlU6WoBgR","colab_type":"text"},"source":["**Classification Reports**:\n"," - Classification reports do show signs that total accuracy, F1 score, precision, and recall can be improved, yet results seem to be adequate.\n"," - However, as loss shows significant increases over epochs, it is a clear sign that the model may not generalize well. As training progressed the validation showed that the model became more uncertain of the predictions that were made."]},{"cell_type":"code","metadata":{"id":"w_kNzwerQfy6","colab_type":"code","colab":{}},"source":["print('Classification Report: Model 1A \\n', metrics.classification_report(y_true, y_pred_1A, target_names=y_true_lab))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MH6bpFwbgmU0","colab_type":"code","colab":{}},"source":["# Classification report heatmap\n","plot_classification_report(y_true, y_pred_1A, (12,10))\n","#plt.yticks('Cat', 'Dog')\n","plt.ylabel('Classes')\n","plt.xlabel('Scores')\n","plt.title('Classification Heatmap: Model 1A', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnP93VqXo2o7","colab_type":"text"},"source":["**Confusion Matrix:**\n"," - Confusion matrix shows that 2750 cat images were correctly classified as not dogs, or the negative class. 398 were wrongly classified as dogs (false positives). 390 were wrongly classified as not dogs, or false negatives, and 2712 were correctly classified as dogs, or true positives.\n"]},{"cell_type":"code","metadata":{"id":"oFw6aOnRYw6Y","colab_type":"code","colab":{}},"source":["conf_mx1 = confusion_matrix(y_true, y_pred_1A)\n","plt.figure(figsize=(12,10))\n","plot_confusion_matrix(conf_mx1, True, None , 'Blues')\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix: Model 1A', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fp2tF9M3AJfu","colab_type":"text"},"source":["**Run Model on Test Set:**"]},{"cell_type":"code","metadata":{"id":"U2xfqTZZMGxM","colab_type":"code","colab":{}},"source":["STEP_SIZE_TEST=test_data_gen.n//test_data_gen.batch_size\n","test_data_gen.reset()\n","pred = model_1A.predict_generator(test_data_gen,\n","steps=STEP_SIZE_TEST,\n","verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZjK91sTPDNA1","colab_type":"code","colab":{}},"source":["submission = pd.DataFrame(pred, columns=['label'])\n","submission.index = np.arange(1,len(submission)+1)\n","submission.reset_index(inplace=True)\n","submission.rename(columns={'index':'id'}, inplace=True)\n","submission.to_csv('submission.csv', index=False)\n","from google.colab import files\n","files.download(\"submission.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxGRruQLnFqt","colab_type":"text"},"source":["**User Name: abehzad, Kaggle Score: 2.0117**"]},{"cell_type":"code","metadata":{"id":"Y_ucVf_Op705","colab_type":"code","colab":{}},"source":["#Store test result in variable\n","Test_1A = 2.01172"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EJB6t3PH_xph","colab_type":"text"},"source":["**Save Model:**"]},{"cell_type":"code","metadata":{"id":"HE8Zb9Rw1sCt","colab_type":"code","colab":{}},"source":["t = time.time()\n","export_path_model_1A = \"./tmp/saved_models_1A.h5/{}\".format(int(t))\n","model_1A.save(export_path_model_1A, save_format='tf')\n","\n","export_path_model_1A"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpKJjh37l3Ku","colab_type":"text"},"source":["### **Model 1B:**\n"," - Batch normalization used after each convolutional layer, and for the fully connected layer.\n"," - Dropout of 0.25 is used for after every max pooling layer and fully connected layer.\n"," - Five convolutional layers, five max pooling layers, and one fully connected layer. \n"," - Nodes for convolutional layers are 3, 64, 128, and 512.\n"," - Fully connected layer has 512 nodes.\n"," - Early stopping set to 5 epochs where the least amount of loss is restored for testing."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qJp7BJOwqU2w","colab":{}},"source":["# Clear session and define model parameters\n","tf.keras.backend.clear_session()\n","\n","model_1B = Sequential([\n","    Conv2D(3, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D(),\n","    Dropout(0.25),\n","    AveragePooling2D(),\n","    Flatten(),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Dropout(0.25),\n","    Dense(512, activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Dropout(0.25),\n","    Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C3X06QGXqU3K","colab":{}},"source":["#compile model and define optimizers\n","model_1B.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy', f1_m, precision_m, recall_m])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dIY-bvGvqU3O","colab":{}},"source":["#model summary\n","model_1B.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YMA9DyH5qU3R","colab":{}},"source":["#Run model with execution time recorded\n","start = timer()\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n","history_1B = model_1B.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch=train_size // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=val_size // batch_size,\n","    callbacks = [es, tbCallBack]\n",")\n","end = timer()\n","exec_time_model_1b = (end - start)/60\n","\n","print('Total Processing Time in Minutes:', exec_time_model_1b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lie-zDvRVybt","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"THLU6kGAQe_d"},"source":["**Metrics and Visualizations:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P0UdFad6Qe_k","colab":{}},"source":["stats_train_1B = model_1B.evaluate(train_data_gen, verbose=1)\n","stats_val_1B = model_1B.evaluate(val_data_gen, verbose=1)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eI2quo4UzAxp"},"source":["**Learning Curves:**\n"," - Learning curves below show signs that there is significantly less overfitting than before. \n"," - Accuracy is much higher, and validation loss is more in line with training loss, where there overall gap is much narrow than the model that did not use regularization and batch normalization."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DO0HKLFZQe_r","colab":{}},"source":["acc_1B = history_1B.history['accuracy']\n","val_acc_1B = history_1B.history['val_accuracy']\n","\n","loss_1B = history_1B.history['loss']\n","val_loss_1B = history_1B.history['val_loss']\n","\n","epochs_range = range(17)\n","\n","plt.figure(figsize=(12, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc_1B, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_1B, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy: Model 1B')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss_1B, label='Training Loss')\n","plt.plot(epochs_range, val_loss_1B, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss: Model 1B')\n","\n","plt.suptitle('Accuracy and Loss: Model 1B', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bjjvMw3DzLzG"},"source":["**F1 Scores, Precision, and Recall:**\n"," - F1 scores, precision and recall show better improvements with regularization and batch normalization. The training and validation F1 scores over epochs show that the trade-offs between precision and recall are better in this model.\n"," - Although the plot shows that there is a significant drop in recall around the fourth epoch, there was significant recovery afterward. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vY2GbxXCQe_v","colab":{}},"source":["f1_1B = history_1B.history['f1_m']\n","val_f1_1B = history_1B.history['val_f1_m']\n","\n","precision_1B = history_1B.history['precision_m']\n","val_precision_1B = history_1B.history['val_precision_m']\n","\n","recall_1B = history_1B.history['recall_m']\n","val_recall_1B = history_1B.history['val_recall_m']\n","\n","\n","f,(ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 8))\n","plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=None)\n","\n","ax1.plot(epochs_range, f1_1B, label='Training F1 Score')\n","ax1.plot(epochs_range, val_f1_1B, label='Validation F1 Score')\n","ax1.legend(loc='lower right')\n","ax1.title.set_text('Training and Validation F1 Score: Model 1B')\n","\n","ax2.plot(epochs_range, precision_1B, label='Training Precision')\n","ax2.plot(epochs_range, val_precision_1B, label='Validation Precision')\n","ax2.legend(loc='lower right')\n","ax2.title.set_text('Training and Validation Precision: Model 1B')\n","\n","ax3.plot(epochs_range, recall_1B, label='Training Recall')\n","ax3.plot(epochs_range, val_recall_1B, label='Validation Recall')\n","ax3.legend(loc='lower right')\n","ax3.title.set_text('Training and Validation Recall: Model 1B')\n","\n","plt.suptitle('F1 Score, Precision, and Recall: Model 1B', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w4eXiVOUQe_z","colab":{}},"source":["val_data_gen.reset()\n","y_pred_1B = model_1B.predict_generator(val_data_gen, val_size // batch_size + 1)\n","y_pred_1B = np.round_(y_pred_1B)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"s6gCWYI1Qe_2","colab":{}},"source":["y_true = val_data_gen.classes[val_data_gen.index_array]\n","y_true_lab = list(val_data_gen.class_indices.keys())   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7Ojbb2dVzUfe"},"source":["**Classification Reports**:\n"," - Classification reports do show signs that total accuracy, F1 score, precision, and recall have significantly improved.\n"," - As loss shows significant decreases over epochs, it is a sign that the model may generalize well. As training progressed validation loss showed that the model became more certain of predictions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M2LSnam5Qe_4","colab":{}},"source":["print('Classification Report: Model 1B \\n', metrics.classification_report(y_true, y_pred_1B, target_names=y_true_lab))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aJlVo0p9Qe_6","colab":{}},"source":["# Classification report heatmap\n","plot_classification_report(y_true, y_pred_1B, (12,10))\n","#plt.yticks('Cat', 'Dog')\n","plt.ylabel('Classes')\n","plt.xlabel('Scores')\n","plt.title('Classification Heatmap: Model 1B', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"or0jyIsuzokK"},"source":["**Confusion Matrix:**\n"," - Confusion matrix shows that 2971 cat images were correctly classified as not dogs, or the negative class. 177 were wrongly classified as dogs (false positives). 264 were wrongly classified as not dogs, or false negatives, and 2838 were correctly classified as dogs, or true positives.  \n"," - As F1 scores, precision, and recall were significantly improved in this model, the improvement is also apparent in the confusion matrix, as there are less false positives and false negatives.    "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YQ8bxUgpQe_8","colab":{}},"source":["conf_mx2 = confusion_matrix(y_true, y_pred_1B)\n","plt.figure(figsize=(12,10))\n","plot_confusion_matrix(conf_mx2, True, None , 'Blues')\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix: Model 1B', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7pu8hvvZ2E_q"},"source":["**Run Model on Test Set:**"]},{"cell_type":"code","metadata":{"id":"etvZViLNXgJM","colab_type":"code","colab":{}},"source":["STEP_SIZE_TEST=test_data_gen.n//test_data_gen.batch_size\n","test_data_gen.reset()\n","pred_1B = model_1B.predict_generator(test_data_gen,\n","steps=STEP_SIZE_TEST,\n","verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qwYaqmI-8dBc","colab_type":"code","colab":{}},"source":["pred_1B"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8hBIC0yI2E_t","colab":{}},"source":["submission_1B = pd.DataFrame(pred_1B, columns=['label'])\n","submission_1B.index = np.arange(1,len(submission_1B)+1)\n","submission_1B.reset_index(inplace=True)\n","submission_1B.rename(columns={'index':'id'}, inplace=True)\n","submission_1B.to_csv('submission_1B.csv', index=False)\n","from google.colab import files\n","files.download(\"submission_1B.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"er4HWR0bQs4H"},"source":["**User Name: abehzad, , Kaggle Score: 3.93058**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yB99WL4gQs4N","colab":{}},"source":["#Store test result in variable\n","Test_1B = 3.93058"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bnu7oCY62E_G"},"source":["**Save Model:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nmCU9YdE2E_a","colab":{}},"source":["t = time.time()\n","export_path_model_1B = \"/tmp/saved_models_1B.h5/{}\".format(int(t))\n","model_1B.save(export_path_model_1B, save_format='tf')\n","\n","export_path_model_1B"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9CXYFeJfyp1","colab_type":"text"},"source":["## **Experimental Factor 2:**\n"," - Each model in the following experimental factor used a different mix of layers and nodes that were inspired by the VGG16 architecture.\n"," - As loss began to rise where model training had to be stopped through early stopping in experimental factor 1, it seemed that this may have been due to overfitting. Therefore, data was augmented in experimental factor 2.\n"," - The first model used a scaled down version of VGG16 with less layers and less nodes. \n"," - The second model also used a modified version of VGG16, yet with almost the same amount of layers. The amount of feature nodes were different, as well as the usage of dropouts and batch normalization. Dropouts were used after every max pooling layer and for the two fully connected layers. \n"," -Early stopping was used for both models that were set to the least amount of loss. Models were ran over 50 epochs with a batch size of 32, with 585 steps per epoch for training, and 195 steps for validation.\n"," - The first model did not do well, as the model could not converge to an optimal solution. This was likely due to a vanishing gradients problem. Vanishing gradients are usually resolvable through batch normalization. A vanishing gradients problem occurs when parameters are updated through backpropagation, and gradients get small enough to the point where the Gradient Descent update leaves the lower connection weights virtually unchanged, and training never converges to a good solution [1].  \n"," - Therefore, in the second model, batch normalization and regularization using dropout were heavily used, and the model was able to converge to an optimal solution. Although the optimal solution could have been better with more training over epochs, the results were indeed adequate.  "]},{"cell_type":"markdown","metadata":{"id":"OxtFAvxBVAeT","colab_type":"text"},"source":["### **Data Augmentation**:\n","Overfitting generally occurs when there are a small number of training examples. One way to approach this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation involves generating more training data from existing training samples by augmenting the samples using random transformations that yield more images. This helps the model by adding more aspects of the data to generalize better [3]. In experimental factor two, data augmentation was used, where augmentations were passed randomly throughout the dataset."]},{"cell_type":"markdown","metadata":{"id":"jsz2c5u6jpdL","colab_type":"text"},"source":["**Training Images with Horizontal Flip:**"]},{"cell_type":"code","metadata":{"id":"waWcRZq4jLzf","colab_type":"code","colab":{}},"source":["image_generator = ImageDataGenerator(rescale=1./255, horizontal_flip=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nubBfZyUipob","colab":{}},"source":["train_data_gen = image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory='./train_train',\n","                                                           shuffle=True,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary',\n","                                                           seed=42)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0uUAv0twjTYd","colab_type":"code","colab":{}},"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"acmzukzijaxC","colab_type":"code","colab":{}},"source":["# Re-use the same custom plotting function defined and used\n","# above to visualize the training images\n","plotImages(augmented_images)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9wKEm59Jjl6y","colab_type":"text"},"source":["**Training Images with 45 Degree Rotation:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Mc7aZCR8jh5X","colab":{}},"source":["image_generator = ImageDataGenerator(rescale=1./255, rotation_range=45)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EhnGz_r2jh5g","colab":{}},"source":["train_data_gen = image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory='./train_train',\n","                                                           shuffle=True,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary',\n","                                                           seed=42)\n","augmented_images = [train_data_gen[0][0][0] for i in range(5)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_anDSdJAjjQj","colab":{}},"source":["plotImages(augmented_images)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xSR1e2R3kEN2","colab_type":"text"},"source":["**Training Images with Zoom:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g5WQPFJgjjQJ","colab":{}},"source":["image_generator = ImageDataGenerator(rescale=1./255, zoom_range=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NkJ8sIi6jjQZ","colab":{}},"source":["train_data_gen = image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory='./train_train',\n","                                                           shuffle=True,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary',\n","                                                           seed=42)\n","augmented_images = [train_data_gen[0][0][0] for i in range(5)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V2MHyLCsjh5p","colab":{}},"source":["plotImages(augmented_images)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCLN4We0kfrz","colab_type":"text"},"source":["**Training Images Prepared with All Augmentations:**"]},{"cell_type":"code","metadata":{"id":"EQz32vookheL","colab_type":"code","colab":{}},"source":["train_data_gen.reset()\n","train_image_generator = ImageDataGenerator(rescale=1./255,\n","                                           rotation_range=45,\n","                                           width_shift_range=.15,\n","                                           height_shift_range=.15,\n","                                           horizontal_flip=True,\n","                                           zoom_range=0.5\n","                                           )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZlM08itFk9Kj","colab_type":"code","colab":{}},"source":["train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                           directory='./train_train',\n","                                                           shuffle=True,\n","                                                           color_mode='rgb',\n","                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                           class_mode='binary',\n","                                                           seed=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7bwXy5TlsXo","colab_type":"code","colab":{}},"source":["augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n","plotImages(augmented_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7cLGil7fipoE","colab":{}},"source":["val_data_gen.reset()\n","validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DQC4a9S1ipok","colab":{}},"source":["val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n","                                                              directory='./train_valid',\n","                                                              shuffle=True,\n","                                                              color_mode='rgb',\n","                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n","                                                              class_mode='binary',\n","                                                              seed=42\n","                                                              )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WLxyqfVLqvgU","colab_type":"text"},"source":["### **Model 2A:**\n"," - Model is inspired from the VGG16 architecture.\n"," - No normalization is applied.\n"," - 0.5 dropout is applied for the two fully connected layers.\n"," - Due to number of images and time and resources, the number of convolutional filters are cut in half, and fully connected layers are scaled down from the 4096 nodes used in VGG16 to 256 nodes.\n"," - Early stopping is used where the model is stopped after 5 epochs if there are no signs of improvement. "]},{"cell_type":"code","metadata":{"id":"6NiDGc2AfNEw","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","\n","model_2A = Sequential([\n","    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","    Conv2D(32, 3, padding='same', activation='relu'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dropout(0.5),\n","    Dense(256, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9eSOHmLqq9NO","colab":{}},"source":["model_2A.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',f1_m, precision_m, recall_m])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PUnj4bSDq9Nj","colab":{}},"source":["model_2A.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"I0vgkCUorRnR","colab":{}},"source":["start = timer()\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n","\n","history_2A = model_2A.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch=train_size // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=val_size // batch_size,\n","    callbacks = [es, tbCallBack]\n",")\n","end = timer()\n","exec_time_model_2a = (end - start)/60\n","\n","print('Total Processing Time in Minutes:', exec_time_model_2a)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rsb2-P42zIt5","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lfMmjOn7d2ms"},"source":["**Metrics and Visualizations:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0xcpCkzJd2m6","colab":{}},"source":["stats_train_2A = model_2A.evaluate(train_data_gen, verbose=1)\n","stats_val_2A = model_2A.evaluate(val_data_gen, verbose=1)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PxSj5hiV4sJn"},"source":["**Learning Curves:**\n"," - Learning curves below show that accuracy and loss curves are close, yet the high loss shows that the model may be underfitting. \n"," - This is in stark contrast to the models in experimental factor 1.\n"," - The poor performance of the model may be due to a vanishing gradients problem as training never converged to a good solution."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l8i6ZhVKd2nH","colab":{}},"source":["acc_2A = history_2A.history['accuracy']\n","val_acc_2A = history_2A.history['val_accuracy']\n","\n","loss_2A = history_2A.history['loss']\n","val_loss_2A = history_2A.history['val_loss']\n","\n","epochs_range = range(6)\n","\n","plt.figure(figsize=(12, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc_2A, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_2A, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy: Model 2A')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss_2A, label='Training Loss')\n","plt.plot(epochs_range, val_loss_2A, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss: Model 2A')\n","\n","plt.suptitle('Accuracy and Loss: Model 2A', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AN7gY8zf41Yq"},"source":["**F1 Scores, Precision, and Recall:**\n"," - F1 scores, precision and recall shows that the model struggled to learn in training. Validation recall was consistently at 1.0 while precision maintained a score of 0.5. This negatively affected the F1 score.   "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9hkxtGjkd2nP","colab":{}},"source":["f1_2A = history_2A.history['f1_m']\n","val_f1_2A = history_2A.history['val_f1_m']\n","\n","precision_2A = history_2A.history['precision_m']\n","val_precision_2A = history_2A.history['val_precision_m']\n","\n","recall_2A = history_2A.history['recall_m']\n","val_recall_2A = history_2A.history['val_recall_m']\n","\n","\n","f,(ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 8))\n","plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=None)\n","\n","ax1.plot(epochs_range, f1_2A, label='Training F1 Score')\n","ax1.plot(epochs_range, val_f1_2A, label='Validation F1 Score')\n","ax1.legend(loc='lower right')\n","ax1.title.set_text('Training and Validation F1 Score: Model 2A')\n","\n","ax2.plot(epochs_range, precision_2A, label='Training Precision')\n","ax2.plot(epochs_range, val_precision_2A, label='Validation Precision')\n","ax2.legend(loc='lower right')\n","ax2.title.set_text('Training and Validation Precision: Model 2A')\n","\n","ax3.plot(epochs_range, recall_2A, label='Training Recall')\n","ax3.plot(epochs_range, val_recall_2A, label='Validation Recall')\n","ax3.legend(loc='lower right')\n","ax3.title.set_text('Training and Validation Recall: Model 2A')\n","\n","plt.suptitle('F1 Score, Precision, and Recall: Model 2A', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mo4vfOard2nb","colab":{}},"source":["val_data_gen.reset()\n","y_pred_2A = model_2A.predict_generator(val_data_gen, val_size // batch_size + 1)\n","y_pred_2A = np.round_(y_pred_2A)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NH3G9bW1d2nh","colab":{}},"source":["y_true = val_data_gen.classes[val_data_gen.index_array]\n","y_true_lab = list(val_data_gen.class_indices.keys())   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RpPYbli84-fo"},"source":["**Classification Reports**:\n"," - Classification reports show signs that total accuracy, F1 score, precision, and recall need significant improvement. At 100% recall it detects 50% of cats while the model had 0 precision, recall, and F1 scores on dogs. This is an indication of the model's uncertainty of making predictions.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C5L_FAUPd2no","colab":{}},"source":["print('Classification Report: Model 2A \\n', metrics.classification_report(y_true, y_pred_2A, target_names=y_true_lab))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gGecqYDOd2nu","colab":{}},"source":["# Classification report heatmap\n","plot_classification_report(y_true, y_pred_2A, (12,10))\n","plt.ylabel('Classes')\n","plt.xlabel('Scores')\n","plt.title('Classification Heatmap: Model 2A', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JO1-2o5G5Esp"},"source":["**Confusion Matrix:**\n"," - The confusion matrix is unreliable and cannot be used for interpretation."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N7o8VuT0d2ny","colab":{}},"source":["conf_mx3 = confusion_matrix(y_true, y_pred_2A)\n","plt.figure(figsize=(12,10))\n","plot_confusion_matrix(conf_mx3, True, None , 'Blues')\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix: Model 2A', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cQRLvBRQd2n2"},"source":["**Run Model on Test Set:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CFIVMQaId2n3","colab":{}},"source":["STEP_SIZE_TEST=test_data_gen.n//test_data_gen.batch_size\n","test_data_gen.reset()\n","pred_2A = model_2A.predict_generator(test_data_gen,\n","steps=STEP_SIZE_TEST,\n","verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2COXpnylpuR","colab_type":"code","colab":{}},"source":["pred_2A"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Sg-gmAMSd2n8","colab":{}},"source":["submission_2A = pd.DataFrame(pred_2A, columns=['label'])\n","submission_2A.index = np.arange(1,len(submission_2A)+1)\n","submission_2A.reset_index(inplace=True)\n","submission_2A.rename(columns={'index':'id'}, inplace=True)\n","submission_2A.to_csv('submission_2A.csv', index=False)\n","from google.colab import files\n","files.download(\"submission_2A.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UK8r61hjd2oC"},"source":["**User Name: abehzad, Kaggle Score: 0.69318**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z4n02sGZd2oD","colab":{}},"source":["#Store test result in variable\n","Test_2A = 0.69318"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tbt9zN8Hd2oH"},"source":["**Save Model:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CZow-ONod2oH","colab":{}},"source":["t = time.time()\n","export_path_model_2A = \"/tmp/saved_models_2A.h5/{}\".format(int(t))\n","model_1B.save(export_path_model_1B, save_format='tf')\n","\n","export_path_model_2A"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MvyRRiy4mrrl"},"source":["### **Model 2B:**\n"," - While this model is different than model 2A, it is still a modified version of the VGG16 architecture.\n"," - 0.25 dropouts are applied after every max pooling layer, the 2 fully connected layers with 1024 nodes and 512 nodes have a dropout of 0.25 and and 0.5, respectively.\n"," - Though there are different numbers of feature nodes, the amount of layers are almost the same as what is used in the VGG16 architecture.\n"," - However, there are many dropouts that are applied, and every convolutional layer and fully connected layer is batch normalized.\n"," - There are 13 convolutional layers, 5 max pooling layers, 2 fully connected layers, and one global average pooling layer (similar to adaptive pooling).\n"," - There is zero padding for convolutional layers, max pooling layers use a 2 x 2 kernel and a stride of 2.\n"," - All layers use ReLu activation except for the output layer, which uses sigmoid.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HiKOeYgqmrr0","colab":{}},"source":["tf.keras.backend.clear_session()\n","\n","model_2B = Sequential([\n","    Conv2D(3, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Dropout(0.25),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Dropout(0.25),\n","    Conv2D(128, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Dropout(0.25),\n","    Conv2D(256, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Dropout(0.25),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Conv2D(512, 3, padding='same', activation='relu'),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    MaxPooling2D((2,2), strides=(2,2)),\n","    Dropout(0.25),\n","    GlobalAveragePooling2D(),\n","    Flatten(),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Dense(1024, activation='relu'),\n","    Dropout(0.25),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    BatchNormalization(axis=1, momentum=0.1, epsilon=1e-05, center=True, scale=True, moving_variance_initializer='ones'),\n","    Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d9vhUe2dmrr-","colab":{}},"source":["model_2B.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',f1_m, precision_m, recall_m])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tTmuybxPmrsE","colab":{}},"source":["model_2B.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yyi6YTTZmrsN","colab":{}},"source":["start = timer()\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8, restore_best_weights=True)\n","\n","history_2B = model_2B.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch=train_size // batch_size,\n","    epochs=epochs,\n","    validation_data=val_data_gen,\n","    validation_steps=val_size // batch_size,\n","    callbacks = [es, tbCallBack]\n",")\n","end = timer()\n","exec_time_model_2b = (end - start)/60\n","\n","print('Total Processing Time in Minutes:', exec_time_model_2b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6XQXVVdezPMf","colab":{}},"source":["tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2LGb_Ln3mrsP"},"source":["**Metrics and Visualizations:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"547HFBdWmrsQ","colab":{}},"source":["stats_train_2B = model_2B.evaluate(train_data_gen, verbose=1)\n","stats_val_2B = model_2B.evaluate(val_data_gen, verbose=1)  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jDnCXwQh6I4S"},"source":["**Learning Curves:**\n"," - Learning curves below show better signs of fitting, indicating that the model would generalize well to new data.\n"," - As epochs increase accuracy and loss only get better. It is presumable that accuracy and loss would show more improvement if more epochs were set in training the model.\n"," - Model 2B was the only model where it was not cutoff through early stopping. All other models showed increases in loss and decreases in accuracy as they were stopped."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yZkQi_hOmrsT","colab":{}},"source":["acc_2B = history_2B.history['accuracy']\n","val_acc_2B = history_2B.history['val_accuracy']\n","\n","loss_2B = history_2B.history['loss']\n","val_loss_2B = history_2B.history['val_loss']\n","\n","epochs_range = range(50)\n","\n","plt.figure(figsize=(12, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc_2B, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc_2B, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy: Model 2B')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss_2B, label='Training Loss')\n","plt.plot(epochs_range, val_loss_2B, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss: Model 2B')\n","\n","plt.suptitle('Accuracy and Loss: Model 2B', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m751Kcb66SNr"},"source":["**F1 Scores, Precision, and Recall:**\n"," - F1 scores, precision, and recall show better improvements using an architecture similar to VGG16 with regularization and batch normalization.  The training and validation F1 scores over epochs show that the trade-offs between precision and recall are better in this model overall."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mx4ctyikmrsY","colab":{}},"source":["f1_2B = history_2B.history['f1_m']\n","val_f1_2B = history_2B.history['val_f1_m']\n","\n","precision_2B = history_2B.history['precision_m']\n","val_precision_2B = history_2B.history['val_precision_m']\n","\n","recall_2B = history_2B.history['recall_m']\n","val_recall_2B = history_2B.history['val_recall_m']\n","\n","\n","f,(ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False, figsize=(20, 8))\n","plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=None)\n","\n","ax1.plot(epochs_range, f1_2B, label='Training F1 Score')\n","ax1.plot(epochs_range, val_f1_2B, label='Validation F1 Score')\n","ax1.legend(loc='lower right')\n","ax1.title.set_text('Training and Validation F1 Score: Model 2B')\n","\n","ax2.plot(epochs_range, precision_2B, label='Training Precision')\n","ax2.plot(epochs_range, val_precision_2B, label='Validation Precision')\n","ax2.legend(loc='lower right')\n","ax2.title.set_text('Training and Validation Precision: Model 2B')\n","\n","ax3.plot(epochs_range, recall_2B, label='Training Recall')\n","ax3.plot(epochs_range, val_recall_2B, label='Validation Recall')\n","ax3.legend(loc='lower right')\n","ax3.title.set_text('Training and Validation Recall: Model 2B')\n","\n","plt.suptitle('F1 Score, Precision, and Recall: Model 2B', fontsize='15')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g93mlHvYmrsa","colab":{}},"source":["val_data_gen.reset()\n","y_pred_2B = model_2B.predict_generator(val_data_gen, val_size // batch_size + 1)\n","y_pred_2B = np.round_(y_pred_2B)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hRh_H0p0mrsd","colab":{}},"source":["y_true = val_data_gen.classes[val_data_gen.index_array]\n","y_true_lab = list(val_data_gen.class_indices.keys())   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ePUfWYU36ZNK"},"source":["**Classification Reports**:\n","\n"," - Classification reports further confirm that total accuracy, F1 score, precision, and recall were better in this model than all the others.\n"," - As loss showed significant decreases over epochs all the way to the end, it is a very good sign that the model would generalize better than the other models. As training progressed towards the end, validation loss showed that the model became more and more certain of predictions.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rHSMcyjzmrsf","colab":{}},"source":["print('Classification Report: Model 2B \\n', metrics.classification_report(y_true, y_pred_2B, target_names=y_true_lab))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AVq1oEhZmrsi","colab":{}},"source":["# Classification report heatmap\n","plot_classification_report(y_true, y_pred_2B, (12,10))\n","#plt.yticks('Cat', 'Dog')\n","plt.ylabel('Classes')\n","plt.xlabel('Scores')\n","plt.title('Classification Heatmap: Model 2B', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cRk4Me7q6hAa"},"source":["**Confusion Matrix:**\n"," \n"," - Out of all of the models in this experiment, this model using an architecture similar to VGG16 with batch normalization and dropout, had the least false positives and false negatives, which are also supported by the F1 scores, precision, and recall.  "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y_qTFdz5mrsm","colab":{}},"source":["conf_mx4 = confusion_matrix(y_true, y_pred_2B)\n","plt.figure(figsize=(12,10))\n","plot_confusion_matrix(conf_mx4, True, None , 'Blues')\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix: Model 2B', fontsize='16')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-viPhyMpmrsp"},"source":["**Run Model on Test Set:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"G4n9VJInmrsq","colab":{}},"source":["STEP_SIZE_TEST=test_data_gen.n//test_data_gen.batch_size\n","test_data_gen.reset()\n","pred_2B = model_2B.predict_generator(test_data_gen,\n","steps=STEP_SIZE_TEST,\n","verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjYkuZuPrnc1","colab_type":"code","colab":{}},"source":["sub_2B = pd.DataFrame(pred_2B, columns=['label'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T7ukb_famrss","colab":{}},"source":["submission_2B = pd.DataFrame(pred_2B, columns=['label'])\n","submission_2B.index = np.arange(1,len(submission_2B)+1)\n","submission_2B.reset_index(inplace=True)\n","submission_2B.rename(columns={'index':'id'}, inplace=True)\n","submission_2B.to_csv('submission_2B.csv', index=False)\n","from google.colab import files\n","files.download(\"submission_2B.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"puLUp2ERmrsv"},"source":["**User Name: abehzad, Kaggle Score: 2.62120**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zz-lNIcgmrsx","colab":{}},"source":["#Store test result in variable\n","Test_2B = 2.62120"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4hno5Tr7mrs2"},"source":["**Save Model:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D2zeHx6imrs3","colab":{}},"source":["t = time.time()\n","export_path_model_2B = \"/tmp/saved_models_2B.h5/{}\".format(int(t))\n","model_1B.save(export_path_model_1B, save_format='tf')\n","\n","export_path_model_2B"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_8ePMtBO22N","colab_type":"text"},"source":["### **Comparison of Models:**"]},{"cell_type":"markdown","metadata":{"id":"BJM21HflTp32","colab_type":"text"},"source":["**Accuracy Comparison of Models:**\n"," - Accuracy scores over epochs show that models 1B and 2B of experimental factors were significantly better than their counterparts.\n"," - This is likely due to the application of batch normalization and regularization through using dropouts.\n"," - However, model 1B shows a decrease after the 13th epoch, and if it had not been stopped through early stopping, it is presumable that accuracy would have continued to fall. This is also supported by examining loss, as it began to increase after the 13th epoch.\n"," - Although model 2B stopped training after the 50th epoch, this was not due to early stopping. It is assumed that this would have continued to increase. Due to lack of time and computing resources, this could not be further explored.\n"," - The flat line of model 2A exemplifies that the model had difficulty in converging to an optimal solution. It was not able to train over the data properly, which was a sign of a vanishing gradients problem.\n"]},{"cell_type":"code","metadata":{"id":"6UCHdHAFO3SX","colab_type":"code","colab":{}},"source":["#Plot validation accuracy for all models\n","fig, ax = plt.subplots(figsize=(12,10))\n","ax.plot(val_acc_1A, label='Accuracy Model 1A')\n","ax.plot(val_acc_1B, label='Accuracy Model 1B')\n","ax.plot(val_acc_2A, label='Accuracy Model 2A')\n","ax.plot(val_acc_2B, label='Accuracy Model 2B')\n","plt.grid(which='minor')\n","plt.xticks(np.arange(0, 50, step=1))\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","legend = ax.legend(loc='best', fontsize='x-large' )\n","plt.title('Accuracy Comparison of Models', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-8eUrmsTyfs","colab_type":"text"},"source":["**Loss Comparison of Models:** \n"," - The model with the lowest loss was the second model in the second experimental factor.\n"," - Curves show that there was a continued decrease over epochs showing signs that it would continue if the model trained over more epochs.\n"," - However, the processing time for model 2B was over 3 hours where it had a loss that was less than model 1B. On the other hand the percentage difference was about 51%. This trade-off should be carefully considered."]},{"cell_type":"code","metadata":{"id":"VCd6Ip60O3i2","colab_type":"code","colab":{}},"source":["#Plot validation loss for all models\n","fig, ax = plt.subplots(figsize=(12,10))\n","ax.plot(val_loss_1A, label='Loss Model 1A')\n","ax.plot(val_loss_1B, label='Loss Model 1B')\n","ax.plot(val_loss_2A, label='Loss Model 2A')\n","ax.plot(val_loss_2B, label='Loss Model 2B')\n","plt.grid(which='minor')\n","plt.xticks(np.arange(0, 50, step=1))\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","legend = ax.legend(loc='best', fontsize='x-large' )\n","plt.title('Loss Comparison of Models', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qaUbFXpFIZS5","colab_type":"text"},"source":["**F1 Scores, Precision, Recall:**\n"," - Curves in each plot below are similar to the accuracy curves with the exception of model 2A, which shows how the model struggled to come to an optimal solution. This is evident when examining the recall curve for model 2A, as it goes from 100% recall all the way down to 0%."]},{"cell_type":"markdown","metadata":{"id":"-njpoFjZT5s_","colab_type":"text"},"source":["**F1 Comparison of Models:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XPOkN3WGQYxL","colab":{}},"source":["#Plot F1 score loss for all models\n","fig, ax = plt.subplots(figsize=(12,10))\n","ax.plot(val_f1_1A, label='Loss Model 1A')\n","ax.plot(val_f1_1B, label='Loss Model 1B')\n","ax.plot(val_f1_2A, label='Loss Model 2A')\n","ax.plot(val_f1_2B, label='Loss Model 2B')\n","plt.grid(which='minor')\n","plt.xticks(np.arange(0, 50, step=1))\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","legend = ax.legend(loc='best', fontsize='x-large' )\n","plt.title('F1 Score Comparison of Models', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qUnrUEHVT_Nt","colab_type":"text"},"source":["**Precision Comparison of Models:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0JBXdAg-QZJI","colab":{}},"source":["#Plot validation precision for all models\n","fig, ax = plt.subplots(figsize=(12,10))\n","ax.plot(val_precision_1A, label='Loss Model 1A')\n","ax.plot(val_precision_1B, label='Loss Model 1B')\n","ax.plot(val_precision_2A, label='Loss Model 2A')\n","ax.plot(val_precision_2B, label='Loss Model 2B')\n","plt.grid(which='minor')\n","plt.xticks(np.arange(0, 50, step=1))\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","legend = ax.legend(loc='best', fontsize='x-large' )\n","plt.title('Precision Comparison of Models', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHCdpC8FUFW9","colab_type":"text"},"source":["**Recall Comparison of Models:**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JEHRtaE7QZhe","colab":{}},"source":["#Plot validation recall for all models\n","fig, ax = plt.subplots(figsize=(12,10))\n","ax.plot(val_recall_1A, label='Loss Model 1A')\n","ax.plot(val_recall_1B, label='Loss Model 1B')\n","ax.plot(val_recall_2A, label='Loss Model 2A')\n","ax.plot(val_recall_2B, label='Loss Model 2B')\n","plt.grid(which='minor')\n","plt.xticks(np.arange(0, 50, step=1))\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","legend = ax.legend(loc='best', fontsize='x-large' )\n","plt.title('Recall Comparison of Models', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CBJds7DZUPtr","colab_type":"text"},"source":["**CNN Benchmark Experiment Results:**\n"]},{"cell_type":"code","metadata":{"id":"ahyPFi1pO3xe","colab_type":"code","colab":{}},"source":["#Table for benchmark comparison\n","comparison_df = pd.DataFrame(np.array([['Model 1A', '13',  round(exec_time_model_1a, 2), round(stats_val_1A[1], 5), round(stats_val_1A[0], 5), Test_1A],\n","                                       ['Model 1B', '14',  round(exec_time_model_1b, 2), round(stats_val_1B[1], 5), round(stats_val_1B[0], 5), Test_1B],\n","                                       ['Model 2A', '15',  round(exec_time_model_2a, 2), round(stats_val_2A[1], 5), round(stats_val_2A[0], 5), Test_2A],\n","                                       ['Model 2B', '22',  round(exec_time_model_2b, 2), round(stats_val_2B[1], 5), round(stats_val_2B[0], 5), Test_2B]]),\n","                                      columns=('Model', 'Total CNN Layers', 'Processing Time in Minutes', \n","                                               'Training Set Accuracy', 'Training Loss', 'Test Set Loss'))\n","comparison_df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPum5f2nUiLA","colab_type":"text"},"source":["**Benchmark Processing Time Comparison by Model:**"]},{"cell_type":"code","metadata":{"id":"zhjbMj5MPWo-","colab_type":"code","colab":{}},"source":["#Plot of model processing times:\n","comparison_df['Processing Time in Minutes'] = comparison_df['Processing Time in Minutes'].astype(float) \n","f, ax = plt.subplots(figsize=(15, 10))\n","sns.barplot('Model', 'Processing Time in Minutes', data = comparison_df, color='green')\n","\n","def change_width(ax, new_value) : #Change width of bars\n","    for patch in ax.patches :\n","        current_width = patch.get_width()\n","        diff = current_width - new_value\n","\n","        # we change the bar width\n","        patch.set_width(new_value)\n","\n","        # we recenter the bar\n","        patch.set_x(patch.get_x() + diff * .5)\n","\n","change_width(ax, .35)\n","\n","plt.ylim(0, 250)\n","plt.title('Benchmark Processing Time Comparison by Model', fontsize='15')\n","plt.show();"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IwTcTgSjHEng","colab_type":"text"},"source":["### **Conclusion:**"]},{"cell_type":"code","metadata":{"id":"iWVUkGbsfyyP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}